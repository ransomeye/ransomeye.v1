# ğŸ¤– RANSOMEYE â€” PHASE 8

## AI/ML Inference, Explainability & Analyst Assistance (Day-1 Ready, Advisory Only)

### **(AUTHORITATIVE MASTER PROMPT â€“ PHASE 8)**

**Environment Root:** `/home/ransomeye/rebuild/`
**Phase Folder:** `/home/ransomeye/rebuild/ransomeye_ai/`

---

## CONTEXT (STRICT ISOLATION)

This phase wires **fully trained AI/ML/LLM** into RansomEye **from Day 1** to:

* Reduce analyst load
* Provide explainability
* Provide context and recommendations

**This phase has ZERO enforcement authority.**
**If this phase fails, Core must continue safely.**

---

## ğŸš¨ GLOBAL RULES (RE-ENFORCED)

All rules from **Phase 1â€“7** apply unchanged.

Additional Phase-8 rules below are **hard enforcement**.

---

## ğŸ¯ PHASE 8 OBJECTIVE

Build a **Day-1 ready, fully trained, explainable AI/ML/LLM subsystem** that:

1. Loads **signed baseline models** at startup
2. Performs **read-only inference**
3. Emits **confidence + SHAP** for every numeric output
4. Provides **human-readable explanations**
5. Supports **incremental learning only with explicit approval**
6. Never influences policy or enforcement
7. Operates offline / air-gapped

---

## ğŸ“¦ RESPONSIBILITY BOUNDARIES (STRICT)

### MUST DO

* Verify baseline intelligence packs
* Perform inference deterministically
* Generate SHAP for every inference
* Attach rationale and confidence
* Provide analyst-friendly summaries
* Log every inference for audit

### MUST NEVER DO

* Enforce actions
* Modify Core state
* Retrain implicitly
* Operate without baseline
* Guess without confidence
* Access raw secrets

---

## ğŸ“ PHASE 8 DIRECTORY STRUCTURE (MANDATORY)

Create exactly:

```
/home/ransomeye/rebuild/ransomeye_ai/
```

```
ransomeye_ai/
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ransomware_behavior.model
â”‚   â”‚   â”œâ”€â”€ anomaly_baseline.model
â”‚   â”‚   â””â”€â”€ calibration.model
â”‚   â”œâ”€â”€ shap/
â”‚   â”‚   â””â”€â”€ baseline_shap.json
â”‚   â””â”€â”€ signatures/
â”‚       â””â”€â”€ baseline.sig
â”‚
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ predictor.py
â”‚   â”œâ”€â”€ confidence.py
â”‚   â”œâ”€â”€ safeguards.py
â”‚   â””â”€â”€ invariants.py
â”‚
â”œâ”€â”€ explainability/
â”‚   â”œâ”€â”€ shap_generator.py
â”‚   â”œâ”€â”€ shap_schema.json
â”‚   â””â”€â”€ artifact_writer.py
â”‚
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ runtime.py
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ incident_summary.txt
â”‚   â”‚   â”œâ”€â”€ kill_chain_explain.txt
â”‚   â”‚   â””â”€â”€ analyst_qa.txt
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ index.bin
â”‚   â”‚   â””â”€â”€ retriever.py
â”‚   â””â”€â”€ guardrails.py
â”‚
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ read_only_adapter.rs
â”‚   â””â”€â”€ contract.rs
â”‚
â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ model_verification.py
â”‚   â”œâ”€â”€ prompt_signing.py
â”‚   â””â”€â”€ trust_chain.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ day1_training.md
â”‚   â”œâ”€â”€ inference_flow.md
â”‚   â”œâ”€â”€ explainability.md
â”‚   â”œâ”€â”€ llm_guardrails.md
â”‚   â””â”€â”€ failure_modes.md
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ baseline_presence_tests.py
    â”œâ”€â”€ shap_completeness_tests.py
    â”œâ”€â”€ hallucination_tests.py
    â”œâ”€â”€ drift_detection_tests.py
    â””â”€â”€ integrity_tests.py
```

---

## ğŸ§  DAY-1 TRAINING REQUIREMENTS (MANDATORY)

You MUST ensure:

* Baseline models are **pre-trained before release**
* Training provenance is documented
* Feature schemas are frozen
* Calibration curves included
* SHAP baseline distributions included

If any baseline artifact is missing or invalid:
â¡ï¸ **AI subsystem MUST NOT START**

---

## ğŸ” SHAP EXPLAINABILITY (NON-NEGOTIABLE)

Rules:

* SHAP for **every numeric inference**
* Stored with inference output
* Signed and verifiable
* Human + machine readable

Missing SHAP â†’ **BLOCK inference**

---

## ğŸ§  LLM SOC ASSISTANT (READ-ONLY)

LLM rules:

* Local model only
* Pre-indexed RAG only
* No learning
* No external calls
* Evidence-linked responses
* Confidence disclosure

LLM MUST NOT:

* Suggest actions
* Trigger workflows
* Modify state
* Bypass Core

---

## ğŸ” SECURITY & TRUST (MANDATORY)

You MUST enforce:

* Model signature verification
* Prompt signature verification
* Version pinning
* Trust-chain validation
* Revocation handling

Failure â†’ **Subsystem disabled + audit log**

---

## ğŸ”„ INCREMENTAL LEARNING (CONTROLLED)

Allowed ONLY if:

* Explicit admin approval
* Signed training package
* Offline training
* Re-signing of new baseline
* Full audit trail

No background learning.
No silent updates.

---

## ğŸ’¥ FAILURE MODES (MANDATORY)

Define explicit behavior for:

* Missing baseline
* Invalid signature
* SHAP generation failure
* Drift detected
* LLM hallucination detected

Failures must:

* Degrade safely
* Never affect enforcement
* Be observable

---

## ğŸ§ª VALIDATION REQUIREMENTS

You MUST include tests that:

* Verify Day-1 readiness
* Verify SHAP completeness
* Detect hallucinations
* Detect model tampering
* Validate read-only contracts

---

## ğŸ›‘ FAILURE CONDITIONS (HARD)

Phase 8 is INVALID if:

* AI can start empty
* AI influences policy
* SHAP is optional
* LLM accesses live systems
* Incremental learning is implicit

---

## FINAL INSTRUCTION

Treat Phase 8 as:

* A **trained advisor**
* A **court-defensible explainer**
* A **non-authoritative assistant**

If Phase 8 fails, **humans lose insight but security remains intact**.

**BUILD PHASE 8 COMPLETELY, EXPLICITLY, AND WITHOUT ASSUMPTIONS.**

---
